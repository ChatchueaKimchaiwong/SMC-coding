{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    return (average, math.sqrt(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = 0.91\n",
    "sig = 1\n",
    "beta = 0.5\n",
    "time = 500\n",
    "Xsys = []\n",
    "Ysys = []\n",
    "x0 = np.random.normal(0,(sig**2/(1-al**2))**0.5) # first state\n",
    "y0 = np.random.normal(0,((beta**2)*math.exp(x0))**0.5) #first observation\n",
    "Xsys.append(x0)\n",
    "Ysys.append(y0) \n",
    "\n",
    "for t in range(0,time-1):\n",
    "    x = np.random.normal(al*Xsys[t],sig)\n",
    "    y = np.random.normal(0,((beta**2)*math.exp(x))**0.5)\n",
    "    Xsys.append(x)\n",
    "    Ysys.append(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"Simulated Volatility Sequence\", fontsize = 20)\n",
    "plt.xlabel('time',fontsize=20)\n",
    "#plt.ylabel('x-coordinate', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=time+1, step=1),Xsys,linestyle='-',color='blue',label='Volatility')\n",
    "plt.plot(np.arange(start=1, stop=time+1, step=1),Ysys,'*', color='red',label='Observations')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIS\n",
    "T = 100 #time of filter\n",
    "N = 1000 #number of particles\n",
    "Xsis = np.zeros((T,N)) #matrix of particles for 100 times\n",
    "Wsis = np.zeros((T,N)) #matrix of weight of particles for 100 times\n",
    "Meansis = np.zeros(T) \n",
    "SDsis = np.zeros(T)\n",
    "\n",
    "xsis0 = np.random.normal(0,(sig**2/(1-al**2))**0.5,N) #q(x1|y1)= u(x1) sample particle for first time\n",
    "alsis0 = norm.pdf(Ysys[0], 0, ((beta**2)*np.exp(xsis0))**0.5)\n",
    "wsis0 = alsis0/np.sum(alsis0)  #w1=g(y1|x1)\n",
    "Xsis[0] = xsis0\n",
    "Wsis[0] = wsis0\n",
    "\n",
    "for t in range(0,T-1): \n",
    "    xsis = np.random.normal(al*Xsis[t],sig,N)  #q(xn|yn,xn-1) = f(xn|xn-1)\n",
    "    alsis = norm.pdf(Ysys[t+1], 0, ((beta**2)*np.exp(xsis))**0.5) #calculate incremental weight \\alpha_n = g(yn|xn)\n",
    "    wsis = alsis*Wsis[t]/np.sum(alsis*Wsis[t]) #weight of each particl at time n #wn=\\alpha_n * wn-1\n",
    "    Xsis[t+1] = xsis\n",
    "    Wsis[t+1] = wsis\n",
    "    \n",
    "for k in range(0,T):\n",
    "    weighted_stats = weighted_avg_and_std(Xsis[k], Wsis[k])\n",
    "    Meansis[k] = weighted_stats[0] #filtering mean time n\n",
    "    SDsis[k] = weighted_stats[1] #filtering sd time n\n",
    "    \n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"SIS Filtering Estimates\", fontsize = 20)\n",
    "plt.xlabel('time',fontsize=20)\n",
    "#plt.ylabel('x-coordinate', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Xsys[0:T],marker='+',linestyle='-',color='blue',label='True Volatility')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansis,linestyle='-',linewidth=1,color='red',label='Filter Mean')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansis+SDsis,linestyle='--',linewidth=0.7,color='red',label='+/- 1 S.D')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansis-SDsis,linestyle='--',linewidth=0.7,color='red')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#SIS histogram of particle weights\n",
    "fig, ax = plt.subplots(1,4, figsize=(15,8))\n",
    "fig.suptitle('SIS')\n",
    "\n",
    "ax[0].hist(Wsis[1], np.histogram(Wsis[1])[1])\n",
    "ax[0].set_title(\"n=2\", fontsize = 12)\n",
    "ax[0].set_xlabel('Normalised Weights', fontsize=12)\n",
    "ax[0].set_ylabel('Particle Count', fontsize=12)\n",
    "\n",
    "ax[1].hist(Wsis[9], np.histogram(Wsis[9])[1])\n",
    "ax[1].set_title(\"n=10\", fontsize = 12)\n",
    "ax[1].set_xlabel('Normalised Weights', fontsize=12)\n",
    "\n",
    "ax[2].hist(Wsis[49], np.histogram(Wsis[49])[1])\n",
    "ax[2].set_title(\"n=50\", fontsize = 12)\n",
    "ax[2].set_xlabel('Normalised Weights', fontsize=12)\n",
    "\n",
    "ax[3].hist(Wsis[99], np.histogram(Wsis[99])[1])\n",
    "ax[3].set_title(\"n=100\", fontsize = 12)\n",
    "ax[3].set_xlabel('Normalised Weights', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output size (1,) is not compatible with broadcast dimensions of inputs (1000,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0051eda45692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mal\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mXsis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.normal\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.cont\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.cont_broadcast_2\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.validate_output_shape\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Output size (1,) is not compatible with broadcast dimensions of inputs (1000,)."
     ]
    }
   ],
   "source": [
    "np.random.normal(al*Xsis[0],sig,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMC\n",
    "T = 100 #time of filter\n",
    "N = 1000 #number of particles\n",
    "Xsmc = np.zeros((T,N)) #matrix of particles for 100 times\n",
    "Wsmc = np.zeros((T,N)) #matrix of weight of particles for 100 times\n",
    "Meansmc = np.zeros(T)\n",
    "SDsmc = np.zeros(T)\n",
    "Xb = np.zeros((T,N)) #matrix of resampling particles\n",
    "\n",
    "xsmc0 = np.random.normal(0,(sig**2/(1-al**2))**0.5,N) #q(x1|y1)= u(x1) sample particle for first time\n",
    "alsmc0 = norm.pdf(Ysys[0], 0, ((beta**2)*np.exp(xsmc0))**0.5)\n",
    "wsmc0 = alsmc0/np.sum(alsmc0)  #w1=g(y1|x1)\n",
    "Xsmc[0] = xsmc0\n",
    "Wsmc[0] = wsmc0\n",
    "Xb[0] = np.random.choice(Xsmc[0], N, p= Wsmc[0])\n",
    "\n",
    "for t in range(0,T-1): \n",
    "    xsmc = np.random.normal(al*Xb[t],sig,N)  #q(xn|yn,xn-1) = f(xn|xn-1)\n",
    "    alsmc = norm.pdf(Ysys[t+1], 0, ((beta**2)*np.exp(xsmc))**0.5) #calculate incremental weight \\alpha_n = g(yn|xn)\n",
    "    wsmc = alsmc/np.sum(alsmc) #weight of each particl at time n #wn=\\alpha_n * wn-1\n",
    "    Xsmc[t+1] = xsmc\n",
    "    Wsmc[t+1] = wsmc\n",
    "    Xb[t+1] = np.random.choice(Xsmc[t+1], N, p= Wsmc[t+1])\n",
    "    \n",
    "for k in range(0,T):\n",
    "    weighted_stats = weighted_avg_and_std(Xsmc[k], Wsmc[k])\n",
    "    Meansmc[k] = weighted_stats[0] #filtering mean time n\n",
    "    SDsmc[k] = weighted_stats[1] #filtering sd time n\n",
    "    \n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"SMC Filtering Estimates\", fontsize = 20)\n",
    "plt.xlabel('time',fontsize=20)\n",
    "#plt.ylabel('x-coordinate', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Xsys[0:T],marker='+',linestyle='-',color='blue',label='True Volatility')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansmc,linestyle='-',linewidth=1,color='red',label='Filter Mean')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansmc+SDsmc,linestyle='--',linewidth=0.7,color='red',label='+/- 1 S.D')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansmc-SDsmc,linestyle='--',linewidth=0.7,color='red')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#SMC histogram of particle weights\n",
    "fig, ax = plt.subplots(1,4, figsize=(15,8))\n",
    "fig.suptitle('SMC')\n",
    "\n",
    "ax[0].hist(Wsmc[1], np.histogram(Wsmc[1])[1])\n",
    "ax[0].set_title(\"n=2\", fontsize = 12)\n",
    "ax[0].set_xlabel('Normalised Weights', fontsize=12)\n",
    "ax[0].set_ylabel('Particle Count', fontsize=12)\n",
    "\n",
    "ax[1].hist(Wsmc[9], np.histogram(Wsmc[9])[1])\n",
    "ax[1].set_title(\"n=10\", fontsize = 12)\n",
    "ax[1].set_xlabel('Normalised Weights', fontsize=12)\n",
    "\n",
    "ax[2].hist(Wsmc[49], np.histogram(Wsmc[49])[1])\n",
    "ax[2].set_title(\"n=50\", fontsize = 12)\n",
    "ax[2].set_xlabel('Normalised Weights', fontsize=12)\n",
    "\n",
    "ax[3].hist(Wsmc[99], np.histogram(Wsmc[99])[1])\n",
    "ax[3].set_title(\"n=100\", fontsize = 12)\n",
    "ax[3].set_xlabel('Normalised Weights', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMC with smoothing\n",
    "T = 100 #time of filter\n",
    "N = 1000 #number of particles\n",
    "Xsmo = np.zeros((T,N)) #matrix of particles for 100 times\n",
    "Wsmo = np.zeros((T,N)) #matrix of weight of particles for 100 times\n",
    "Meansmo = np.zeros(T)\n",
    "SDsmo = np.zeros(T)\n",
    "Xb = np.zeros((T,N)) #matrix of resampling particles\n",
    "\n",
    "xsmo0 = np.random.normal(0,(sig**2/(1-al**2))**0.5,N) #q(x1|y1)= u(x1) sample particle for first time\n",
    "alsmo0 = norm.pdf(Ysys[0], 0, ((beta**2)*np.exp(xsmo0))**0.5)\n",
    "wsmo0 = alsmo0/np.sum(alsmo0)  #w1=g(y1|x1)\n",
    "Xsmo[0] = xsmo0\n",
    "Wsmo[0] = wsmo0\n",
    "Xb[0] = np.random.choice(Xsmo[0], N, p= Wsmo[0])\n",
    "\n",
    "for t in range(0,T-1): \n",
    "    xsmo = np.random.normal(al*Xb[t],sig,N)  #q(xn|yn,xn-1) = f(xn|xn-1)\n",
    "    alsmo = norm.pdf(Ysys[t+1], 0, ((beta**2)*np.exp(xsmo))**0.5) #calculate incremental weight \\alpha_n = g(yn|xn)\n",
    "    wsmo = alsmo/np.sum(alsmo) #weight of each particl at time n #wn=\\alpha_n * wn-1\n",
    "    Xsmo[t+1] = xsmo\n",
    "    Wsmo[t+1] = wsmo\n",
    "    Xb[t+1] = xsmo\n",
    "    #resampling step\n",
    "    w = np.random.choice(np.arange(0,N), N, p= Wsmo[t+1]) #to find which particle to resampling\n",
    "    for k in np.arange(0,N):\n",
    "        for j in np.arange(0,t+2):\n",
    "            Xb[j][k] = Xb[j][w[k]]\n",
    "    \n",
    "for k in range(0,T):\n",
    "    weighted_stats = weighted_avg_and_std(Xb[k], Wsmo[T-1])\n",
    "    Meansmo[k] = weighted_stats[0] #filtering mean time n\n",
    "    SDsmo[k] = weighted_stats[1] #filtering sd time n\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"SMC Smoothing Estimates\", fontsize = 20)\n",
    "plt.xlabel('time',fontsize=20)\n",
    "#plt.ylabel('x-coordinate', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Xsys[0:T],marker='+',linestyle='-',color='blue',label='True Volatility')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansmo,linestyle='-',linewidth=1,color='red',label='Smoother Mean')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansmo+SDsmo,linestyle='--',linewidth=0.7,color='red',label='+/- 1 S.D')\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),Meansmo-SDsmo,linestyle='--',linewidth=0.7,color='red')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "#numbers of distinct particle\n",
    "num = []\n",
    "for c in np.arange(0,T):\n",
    "    num.append(len(np.unique(Xb[c], return_counts=True)[1]))\n",
    "    \n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"Numbers of distinct particle in time by using SMC Smoothing\", fontsize = 20)\n",
    "plt.xlabel('time',fontsize=20)\n",
    "plt.ylabel('number', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=T+1, step=1),num,marker='o',linestyle='-',color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.28237828375799"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.sum(Wsis[99]**2) #ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
