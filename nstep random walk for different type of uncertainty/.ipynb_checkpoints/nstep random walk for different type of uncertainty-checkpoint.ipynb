{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import sympy\n",
    "from numpy.linalg import inv\n",
    "from sympy import diff\n",
    "from sympy import Symbol\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x, F, sqrtU):\n",
    "    return np.matmul(F, x) + np.matmul(sqrtU, np.random.randn(sqrtU.shape[1]))\n",
    "\n",
    "def observation(x, H, sqrtV):\n",
    "    return np.matmul(H, x) + np.matmul(sqrtV, np.random.randn(sqrtV.shape[1]))\n",
    "\n",
    "def generate_data(F, H, sqrtU, sqrtV, n, xdim, ydim):\n",
    "    x = np.zeros((xdim, n))\n",
    "    y = np.zeros((ydim, n))\n",
    "    x[:, 0] = prediction(x0, F, sqrtU) #state time 1\n",
    "    y[:, 0] = observation(x[:, 0], H, sqrtV) #ob time 1\n",
    "    for k in range(1,n):\n",
    "        x[:, k] = prediction(x[:, k-1], F, sqrtU)\n",
    "        y[:, k] = observation(x[:, k], H, sqrtV)\n",
    "    return x, y\n",
    "\n",
    "def Kalman_filter(y, m0, P0, F, H, U, V, n, xdim, delta):\n",
    "    # Updated mean and variance\n",
    "    mu = np.zeros((xdim, n))\n",
    "    Pu = np.zeros((xdim, xdim, n))\n",
    "    # Predicted mean and variance\n",
    "    mp = np.zeros((xdim, n))\n",
    "    Pp = np.zeros((xdim, xdim, n))\n",
    "    \n",
    "    # Predicted mean and variance t=1\n",
    "    mp[:, 0] = np.matmul(F, m0)\n",
    "    Pp[:, :, 0] = np.matmul(np.matmul(F, P0), F.transpose()) + U\n",
    "    \n",
    "    # Updated mean and variance t=1\n",
    "    z = y[:, 0] - np.matmul(H, mp[:, 0])\n",
    "    S = np.matmul(np.matmul(H, Pp[:, :, 0]), H.transpose()) + V\n",
    "    K = np.matmul(np.matmul(Pp[:, :, 0], H.transpose()), inv(S))\n",
    "    mu[:, 0] = mp[:, 0] + np.matmul(K, z)\n",
    "    Pu[:, :, 0] = np.matmul(np.eye(xdim) - np.matmul(K, H), Pp[:, :, 0])\n",
    "    \n",
    "    # Kalman filter t=2-n\n",
    "    for k in np.arange(1,n):\n",
    "        # Prediction\n",
    "        mp[:, k] = np.matmul(F, mu[:, k-1])\n",
    "        Pp[:, :, k] = np.matmul(np.matmul(F, Pu[:, :, k-1]), F.transpose()) + U\n",
    "        # Update\n",
    "        if k < n - delta:\n",
    "            z = y[:, k] - np.matmul(H, mp[:, k])\n",
    "            S = np.matmul(np.matmul(H, Pp[:, :, k]), H.transpose()) + V\n",
    "            K = np.matmul(np.matmul(Pp[:, :, k], H.transpose()), inv(S))\n",
    "            mu[:, k] = mp[:, k] + np.matmul(K, z)\n",
    "            Pu[:, :, k] = np.matmul(np.eye(xdim) - np.matmul(K, H), Pp[:, :, k])\n",
    "        else:\n",
    "            mu[:, k] = mp[:, k]\n",
    "            Pu[:, :, k] = Pp[:, :, k]\n",
    "        \n",
    "    return mp, Pp, mu, Pu\n",
    "\n",
    "\n",
    "#matrix of transformation for p(x0,x1,...,xn) => p(y1,...,yn)\n",
    "def genH(H,n):\n",
    "    Hv = np.zeros((n, n+1))\n",
    "    for i in np.arange(n):\n",
    "        Hv[i][i+1] = H\n",
    "    return Hv\n",
    "\n",
    "#matrix of mean of joint prior p(x0,x1,...,xn)\n",
    "def genM(F,m0,n):\n",
    "    M = []    \n",
    "    M.append(m0)\n",
    "    for i in np.arange(n):\n",
    "        M.append(np.matmul(F,M[i]))\n",
    "    M = np.array(M)  #array of old mean\n",
    "    return M\n",
    "    \n",
    "#matrix of variance of joint prior p(x0,x1,...,xn)\n",
    "def genP(F,P0,U,n):\n",
    "    P = np.zeros((n+1, n+1))\n",
    "    P[0][0] = P0\n",
    "    for i in np.arange(1,n+1):\n",
    "        P[i][i] = np.matmul(np.matmul(F, [P[i-1][i-1]]), F.transpose()) + U\n",
    "    for j in np.arange(0,n+1):    \n",
    "        for k in np.arange(0,n+1):  \n",
    "            if j < k:\n",
    "                P[j][k] =  np.matmul(F, [P[j][k-1]])\n",
    "                P[k][j] = P[j][k]\n",
    "    return P\n",
    "\n",
    "def KS(y,m0,P0,F,H,U,V,n,start,end):\n",
    "    Mu0 = np.zeros(n) #mean x0|y1:n when n=1,...,n\n",
    "    P00 = np.zeros(n) #var x0|y1:n when n=1,...,n\n",
    "    Mun = np.zeros(n) #mean xn|y1:n when n=1,...,n\n",
    "    Pnn = np.zeros(n) #var xn|y1:n when n=1,...,n\n",
    "    P0n = np.zeros(n) #cov x0,xn|y1:n when n=1,...,n\n",
    "    Mcco = np.zeros(n) #coef of mean xn|x0,y1:n \n",
    "    Mcre = np.zeros(n) #remainder of mean xn|x0,y1:n \n",
    "    Pc = np.zeros(n) #var of xn|x0,y1:n \n",
    "    for h in np.arange(start,end+1):\n",
    "        P = genP(F,P0,U,h)\n",
    "        Hv = genH(H,h)\n",
    "        Vv = np.zeros((h, h))\n",
    "        for i in np.arange(h):\n",
    "            Vv[i][i] = V\n",
    "        S = np.matmul(np.matmul(Hv, P),Hv.transpose()) +Vv\n",
    "        K = np.matmul(np.matmul(P, Hv.transpose()),inv(S)) \n",
    "        M = genM(F,m0,h)\n",
    "        Mu0[h-1] = np.matmul((np.identity(h+1) - np.matmul(K,Hv))[0], M) + np.matmul(K[0],y[0][0:h]) #mean x0|y1:n\n",
    "        Mun[h-1] = np.matmul((np.identity(h+1) - np.matmul(K,Hv))[h], M) + np.matmul(K[h],y[0][0:h]) #mean xn|y1:n\n",
    "        P00[h-1] = np.matmul((np.identity(h+1) - np.matmul(K,Hv))[0],P[:,[0]])\n",
    "        P0n[h-1] = np.matmul((np.identity(h+1) - np.matmul(K,Hv))[0],P[:,[h]])\n",
    "        Pnn[h-1] = np.matmul((np.identity(h+1) - np.matmul(K,Hv))[h],P[:,[h]])\n",
    "        Mcco[h-1] = P0n[h-1]/P00[h-1]\n",
    "        Mcre[h-1] = Mun[h-1] - (Mcco[h-1]* Mu0[h-1])\n",
    "        Pc[h-1] = Pnn[h-1] - (Mcco[h-1]*P0n[h-1])\n",
    "    return Mu0,P00,Mun,Pnn,Mcco,Mcre,Pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of the state and observation\n",
    "xdim = 1\n",
    "ydim = 1\n",
    "\n",
    "# Initial state\n",
    "x0 = np.array([[0]])\n",
    "\n",
    "# Observation matrix = N(yn;xn,1)\n",
    "H = np.array([[1]]) #identity observe\n",
    "\n",
    "# Observation noise\n",
    "sigy=20  #sigy = 20\n",
    "sqrtV = np.array([[sigy]]) #sigma ob\n",
    "V = np.matmul(sqrtV, sqrtV.transpose()) #observation variance\n",
    "\n",
    "# Prior = N(x0;0,1)\n",
    "m0 = np.array([0.0]) #m0=0\n",
    "sig0 =400 #prior sigma , sig0=400\n",
    "P0 = np.array([sig0**2]) #large uncertainty of initial state sig0^2 \n",
    "\n",
    "# Evolution = N(xn+1;xn,1)\n",
    "dt = 1.0\n",
    "F = np.array([[1]]) #identity evolution\n",
    "sigx = 1 #sigx=1\n",
    "sqrtU = np.array([[sigx]]) #sigma evolve\n",
    "U = np.matmul(sqrtU, sqrtU.transpose()) #variance evolve\n",
    "# Time steps\n",
    "n = 50\n",
    "delta = 0 \n",
    "\n",
    "# Data generation\n",
    "(x, y) = generate_data(F, H, sqrtU, sqrtV, n, xdim, ydim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Mu0,P00,Mun,Pnn,Mcco,Mcre,Pc) = KS(y,m0,P0,F,H,U,V,n,1,n)\n",
    "\n",
    "a=-2\n",
    "b=2\n",
    "\n",
    "#rv-rv case\n",
    "cred = norm(Mun, Pnn**0.5).cdf(b) - norm(Mun, Pnn**0.5).cdf(a) \n",
    "\n",
    "#duv-duv case\n",
    "B = [] #maximum value of function = credibility duv-duv case\n",
    "for i in np.arange(n):\n",
    "    if a <= Mun[i] <= b:\n",
    "        B.append(1)\n",
    "    elif Mun[i] < a:\n",
    "        B.append(math.exp((-1/(2*(Pnn[i])))*((a-Mun[i])**2 ))) #f(a)\n",
    "    else :\n",
    "        B.append(math.exp((-1/(2*(Pnn[i])))*((b-Mun[i])**2 ))) #f(b)\n",
    "        \n",
    "X = [] #lower bound for credibility duv-duv case\n",
    "for i in np.arange(n):\n",
    "    if a <= Mun[i] <= b:\n",
    "        if abs(a-Mun[i]) <= abs(b-Mun[i]):\n",
    "            X.append(1-(math.exp((-1/(2*(Pnn[i])))*((a-Mun[i])**2 )))) #1-f(a)\n",
    "        else :\n",
    "            X.append(1-(math.exp((-1/(2*(Pnn[i])))*((b-Mun[i])**2 )))) #1-f(b)\n",
    "    elif Mun[i] < a:\n",
    "        X.append(0) #1-f(mean)\n",
    "    else :\n",
    "        X.append(0) #1-f(mean)\n",
    "        \n",
    "#duv-rv case\n",
    "D = [] #maximum value of function = credibility duv-rv case\n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return (math.exp((-1/(2*P00[i]))*((x-Mu0[i])**2 )))* (norm(Mcco[i]*x + Mcre[i], Pc[i]**0.5).cdf(b) - \n",
    "                                                      norm(Mcco[i]*x + Mcre[i], Pc[i]**0.5).cdf(a))\n",
    "    fj1= f((minimize(lambda x: -f(x),a)).x) #set intial guess =a(left point of interval) \n",
    "    fj2= f((minimize(lambda x: -f(x),b)).x) #set intial guess =b(right point of interval)\n",
    "    fj= max(fj1,fj2) \n",
    "    D.append(fj[0])  \n",
    "\n",
    "Y = [] #lower bound for credibility duv-rv case\n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return 1- ((math.exp((-1/(2*P00[i]))*((x-Mu0[i])**2 )))* (1 - norm(Mcco[i]*x + Mcre[i], Pc[i]**0.5).cdf(b) + \n",
    "                                                          norm(Mcco[i]*x + Mcre[i], Pc[i]**0.5).cdf(a)))\n",
    "    fj1= f((minimize(f,a)).x) #set intial guess =a(left point of interval) \n",
    "    fj2= f((minimize(f,b)).x) #set intial guess =b(right point of interval) \n",
    "    fj= min(fj1,fj2) \n",
    "    Y.append(fj[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"Credibility of $P(X_n \\in (-2,2)| y_{1:n})$ for different types of uncertainty when $\\sigma_{x_{0}} = 400, \\sigma_{x}=1,\\sigma_{y}=20$\", fontsize = 20)\n",
    "plt.xlabel('n',fontsize=20)\n",
    "plt.ylabel('credibility', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=n+1, step=1),cred,linestyle='-',color='blue',label='rv-rv')\n",
    "plt.plot(np.arange(start=1, stop=n+1, step=1),B,linestyle='-',color='red')\n",
    "plt.plot(np.arange(start=1, stop=n+1, step=1),X,linestyle='--',color='red')\n",
    "plt.plot(np.arange(start=1, stop=n+1, step=1),D,linestyle='-',color='purple')\n",
    "plt.plot(np.arange(start=1, stop=n+1, step=1),Y,linestyle='--',color='purple')\n",
    "plt.fill_between(np.arange(start=1, stop=n+1, step=1),B,X, color='red', alpha=0.1,label='range of duv-duv')\n",
    "plt.fill_between(np.arange(start=1, stop=n+1, step=1),D,Y, color='purple', alpha=0.1,label='range of duv-rv')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of using time for finding p(xn|y1:n,x0) between KF iteration and KS with marginalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional method (KF iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "start1 = time.time()\n",
    "mp = [np.matmul(F,[Symbol('x')])] #m1|0\n",
    "Pp = np.zeros((xdim, xdim, n))\n",
    "Pp[:, :, 0] = np.array([sigx**2]) #var1|0\n",
    "mu=[]\n",
    "Pu = np.zeros((xdim, xdim, n))\n",
    "\n",
    "# Updated mean and variance t=1\n",
    "z = y[:, 0] - np.matmul(H, mp[0])\n",
    "S = np.matmul(np.matmul(H, Pp[:, :, 0]), H.transpose()) + V\n",
    "K = np.matmul(np.matmul(Pp[:, :, 0], H.transpose()), inv(S))\n",
    "mu.append(mp[0]+ np.matmul(K, z))\n",
    "Pu[:, :, 0] = np.matmul(np.eye(xdim) - np.matmul(K, H), Pp[:, :, 0])\n",
    "\n",
    "# Kalman filter t=2-n\n",
    "for k in np.arange(1,n):\n",
    "    # Prediction\n",
    "    mp.append(np.matmul(F, mu[k-1]))\n",
    "    Pp[:, :, k] = np.matmul(np.matmul(F, Pu[:, :, k-1]), F.transpose()) + U\n",
    "    # Update\n",
    "    if k < n - delta:\n",
    "        z = y[:, k] - np.matmul(H, mp[k])\n",
    "        S = np.matmul(np.matmul(H, Pp[:, :, k]), H.transpose()) + V\n",
    "        K = np.matmul(np.matmul(Pp[:, :, k], H.transpose()), inv(S))\n",
    "        mu.append(mp[k] + np.matmul(K, z))\n",
    "        Pu[:, :, k] = np.matmul(np.eye(xdim) - np.matmul(K, H), Pp[:, :, k])\n",
    "    else:\n",
    "        mu.append(mp[k])\n",
    "        Pu[:, :, k] = Pp[:, :, k]\n",
    "\n",
    "#coefficient and remainder of x0 for mean of every time step \n",
    "#m = coef*x0 + rem\n",
    "Coef =[]\n",
    "Rem = []\n",
    "for i in np.arange(n):\n",
    "    coef = mu[i][0].diff(Symbol('x'))\n",
    "    rem = mu[i][0] - (coef*Symbol('x'))\n",
    "    Coef.append(float(coef))\n",
    "    Rem.append(float(rem))\n",
    "end1 = time.time()\n",
    "timeuse1 = end1 -start1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update 1 step method (Kalman Smoothing) to find only time step n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start2 = time.time()\n",
    "KS(y,m0,P0,F,H,U,V,n,1,n)\n",
    "end2 = time.time()\n",
    "timeuse2 = end2 -start2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update 1 step method (Kalman Smoothing) to find every time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "start3 = time.time()\n",
    "KS(y,m0,P0,F,H,U,V,n,n,n)\n",
    "end3 = time.time()\n",
    "timeuse3 = end3 -start3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finding $P(x_k | x_{0}, y_{1:k})$ for every timestep $k = 1, \\ldots 200$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF spends time 0.07380318641662598 seconds, while KS spends time 0.19498658180236816 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"KF spends time\", timeuse1, \"seconds, while KS spends time\", timeuse2, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we want to find $P(x_{200} | x_{0}, y_{1:200})$ only,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS spends time 0.022939682006835938 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"KS spends time\", timeuse3, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range of subjective predictive distribution of observation $p(y_n |y_{1:n-1})$\n",
    "\n",
    "From Kalman Filter, we get the predictive distribution of state at time n : $p(x_n-1 |y_{1:n-1},x_0) = \\mathcal{N}(x_{n-1};\\mu_{n-1}(x_0),\\sigma_{n-1}^2)$.<br>\n",
    "Then, we can have $p(x_n |y_{1:n-1},x_0) = \\mathcal{N}(x_{n};F\\mu_{n-1}(x_0),F\\sigma_{n-1}^2F^T + \\sigma_x^2)$.<br>\n",
    "Moreover, from the fact $p(y_n |x_n) = \\mathcal{N}(y_n;Hx_n,\\sigma_y^2)$. <br>\n",
    "Then, $p(y_n |y_{1:n-1},x_0)$ can be calculated by\n",
    "$$p(y_n |y_{1:n-1},x_0) = \\underset{\\mathcal{X}}{\\int}p(y_n |x_n) \\cdot p(x_n |y_{1:n-1},x_0) dx_n = \n",
    "\\mathcal{N}(y_n;HF\\mu_{n-1}(x_0),\\sigma_y^2 + H(F\\sigma_{n-1}^2F^T + \\sigma_x^2) H^T) .$$\n",
    "Since\n",
    "$$1 - \\overline{P}(1-\\varphi) \\hskip0.2cm \\leq \\hskip0.2cm P(\\varphi) \\hskip0.2cm \\leq  \\hskip0.2cm \\overline{P}(\\varphi)$$\n",
    "$$1 - \\underset{x_0 \\in \\mathcal{X}}{sup} [(1- \\varphi(x_0))f(x_0 |y_{1:n-1})] \\hskip0.2cm \\leq \n",
    "\\hskip0.2cm \\underset{\\mathcal{X}}{\\int} \\varphi(x_0)p(x_0 |y_{1:n-1} )dx_0 \\hskip0.2cm\n",
    "\\leq \\hskip0.2cm \\underset{x_0 \\in \\mathcal{X}}{sup}\\varphi(x_0))f(x_0 |y_{1:n-1}),$$\n",
    "By substitute $\\varphi(x_0) = p(y_n |y_{1:n-1},x_0) $, we obtain\n",
    "<br> <br> \n",
    "$$1 - \\underset{x_0 \\in \\mathcal{X}}{sup} [(1-  p(y_n |y_{1:n-1},x_0))f(x_0 |y_{1:n-1})] \\hskip0.2cm \\leq \n",
    "\\hskip0.2cm \\underset{\\mathcal{X}}{\\int} p(y_n |y_{1:n-1},x_0)p(x_0 |y_{1:n-1})dx_0 \\hskip0.2cm\n",
    "\\leq \\hskip0.2cm \\underset{x_0 \\in \\mathcal{X}}{sup} p(y_n |y_{1:n-1},x_0))f(x_0 |y_{1:n-1})$$\n",
    "\n",
    "$$\\underset{x_0 \\in \\mathcal{X}}{min} 1 - [(1-  p(y_n |y_{1:n-1},x_0))f(x_0 |y_{1:n-1})] \\hskip0.2cm \\leq \n",
    "\\hskip0.2cm p(y_n |y_{1:n-1}) \\hskip0.2cm\n",
    "\\leq \\hskip0.2cm \\underset{x_0 \\in \\mathcal{X}}{sup} p(y_n |y_{1:n-1},x_0))f(x_0 |y_{1:n-1}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rv-rv case\n",
    "Mun1  = np.insert(Mun[0:n-1],0,m0) # mean xn-1| y1:n-1 i.e. x0, x1|y1, x2|y1:2, ..., xn-1|y1:n-1\n",
    "Pnn1  = np.insert(Pnn[0:n-1],0,P0) # var xn-1| y1:n-1\n",
    "Myn = []\n",
    "Pyn = []\n",
    "for i in np.arange(n):\n",
    "    Myn.append(np.matmul(H,np.matmul(F,[Mun1[i]])))  #mean yn| y1:n-1\n",
    "    Pyn.append(np.matmul(H,np.matmul(np.matmul(F,np.matmul([Pnn1[i]],F.transpose())) + U, H.transpose())) + V) \n",
    "    #var yn| y1:n-1\n",
    "    \n",
    "#rv-rv case for prob p(yn|y1:n-1)\n",
    "cred = []\n",
    "for i in np.arange(n):\n",
    "    cred.append((norm(Myn[i],Pyn[i]**0.5).pdf(y[0][i])[0])[0])\n",
    "    \n",
    "        \n",
    "        \n",
    "#duv-rv case\n",
    "#yn|x0,y1:n-1\n",
    "Mcco1  = np.insert(Mcco[0:n-1],0,1) #coef of mean xn-1|x0,y1:n-1 i.e. x0, x1|x0,y1, x2|x0,y1:2, ..., xn-1|x0,y1:n-1 #x0 = 1*x + 0\n",
    "Mcre1  = np.insert(Mcre[0:n-1],0,0) #remainder of mean xn-1|x0,y1:n-1 \n",
    "Pc1  = np.insert(Pc[0:n-1],0,P0) #remainder of mean xn-1|x0,y1:n-1 \n",
    "coyn = []  #coef of mean yn|x0,y1:n-1\n",
    "reyn = []  #remainder of mean yn|x0,y1:n-1\n",
    "Pyn = [] #variance yn|x0,y1:n-1\n",
    "for i in np.arange(n):\n",
    "    coyn.append(np.matmul(H,np.matmul(F,[Mcco1[i]])))  \n",
    "    reyn.append(np.matmul(H,np.matmul(F,[Mcre1[i]])))  \n",
    "    Pyn.append((np.matmul(H,np.matmul(np.matmul(F,np.matmul([Pc1[i]],F.transpose())) + U, H.transpose())) + V)[0]) \n",
    "    \n",
    "#x0|y1:n-1\n",
    "newMu0 = np.insert(Mu0[0:n-1],0,m0) #mean x0|y1:n-1 i.e. x0, x0|y1, x0|y1:2, ..., x0|y1:n-1\n",
    "newP00 = np.insert(P00[0:n-1],0,P0) #variance x0|y1:n-1    \n",
    "    \n",
    "    \n",
    "#upper bound for subjective prob p(yn|y1:n-1)\n",
    "D=[]\n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return (math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i]))\n",
    "    #j1 = minimize(lambda x: -f(x),newMu0[i] + (newP00[i]**0.5)).x   ##set intial guess =m0 +- sig0\n",
    "    #j2 = minimize(lambda x: -f(x),newMu0[i] - (newP00[i]**0.5)).x\n",
    "    #fj = max(f(j1),f(j2))\n",
    "    fj = f(minimize(lambda x: -f(x),newMu0[i]).x)\n",
    "    D.append(fj[0])  \n",
    "\n",
    "#lower bound for subjective prob p(yn|y1:n-1)    \n",
    "Y = [] \n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return 1- ((math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (1-norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i]))) \n",
    "    j1 = minimize(f,newMu0[i] + (newP00[i]**0.5)).x  ##set intial guess =m0 +- sig0\n",
    "    j2 = minimize(f,newMu0[i] - (newP00[i]**0.5)).x\n",
    "    fj = min(f(j1),f(j2))\n",
    "    Y.append(fj[0])  \n",
    "    \n",
    "#duv-duv case\n",
    "B =[]#maximum value of function = credibility duv-duv case\n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return (math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))*(math.exp((-1/(2*Pyn[i]))*((y[0][i]-coyn[i]*x + reyn[i])**2 )))\n",
    "    #j1 = minimize(lambda x: -f(x),newMu0[i] + (newP00[i]**0.5)).x   ##set intial guess =m0 +- sig0\n",
    "    #j2 = minimize(lambda x: -f(x),newMu0[i] - (newP00[i]**0.5)).x\n",
    "    #fj = max(f(j1),f(j2))\n",
    "    fj = f(minimize(lambda x: -f(x),newMu0[i]).x)\n",
    "    B.append(fj)\n",
    "\n",
    "X = [] #lower bound for credibility duv-duv case\n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return 1- ((math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (1-(math.exp((-1/(2*Pyn[i]))*((y[0][i]-coyn[i]*x + reyn[i])**2 ))))) \n",
    "    j1 = minimize(f,newMu0[i] + (newP00[i]**0.5)).x  ##set intial guess =m0 +- sig0\n",
    "    j2 = minimize(f,newMu0[i] - (newP00[i]**0.5)).x\n",
    "    fj = min(f(j1),f(j2))\n",
    "    X.append(fj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"Credibility of $p(y_n| y_{1:n-1})$ for different types of uncertainty when $\\sigma_{x_{0}} = 400, \\sigma_{x}=1,\\sigma_{y}=20$\", fontsize = 20)\n",
    "plt.xlabel('n',fontsize=20)\n",
    "plt.ylabel('credibility', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),cred[0:30],linestyle='-',color='blue',label='rv-rv')\n",
    "#plt.plot(np.arange(start=1, stop=31, step=1),B[0:30],linestyle='-',color='red',label='duv-duv')\n",
    "#plt.plot(np.arange(start=1, stop=31, step=1),X[0:30],linestyle='--',color='red',label='lower bound duv-duv')\n",
    "#plt.fill_between(np.arange(start=1, stop=31, step=1),B[0:30],X[0:30], color='red', alpha=0.1,label='range of duv-rv')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),D[0:30],linestyle='-',color='purple',label='upper bound duv-rv')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),Y[0:30],linestyle='--',color='purple',label='lower bound duv-rv')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),D[0:30],Y[0:30], color='purple', alpha=0.1,label='range of duv-rv')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try editing lower bound by $\\underset{x_0 \\in \\mathcal{X}}{min} c - [(c-  p(y_n |y_{1:n-1},x_0))f(x_0 | y_{1:n-1} )]$ where \n",
    "$c = \\underset{x_0 \\in \\mathcal{X}}{max} \\hskip0.2cm p(y_n |y_{1:n-1},x_0)$. <br>\n",
    "If $p(y_n |y_{1:n-1},x_0) = \\mathcal{N} (y_n ; ax_0 +b,var) $This means that we will choose $x_0 = (y_n -b)/a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another lower bound for subjective prob p(yn|y1:n-1)    \n",
    "Y = [] \n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        c = norm(y[0][i], Pyn[i]**0.5).pdf(y[0][i]) #by substitute x0= (yn - rem )/coef we get mean = yn \n",
    "        return c- ((math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (c-norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i])))\n",
    "    j1 = minimize(f,newMu0[i] + (newP00[i]**0.5)).x  ##set intial guess =m0 +- sig0\n",
    "    j2 = minimize(f,newMu0[i] - (newP00[i]**0.5)).x\n",
    "    fj = min(f(j1),f(j2))\n",
    "    Y.append(fj[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"Credibility of $p(y_n| y_{1:n-1})$ for different types of uncertainty when $\\sigma_{x_{0}} = 400, \\sigma_{x}=1,\\sigma_{y}=20$\", fontsize = 20)\n",
    "plt.xlabel('n',fontsize=20)\n",
    "plt.ylabel('credibility', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),cred[0:30],linestyle='-',color='blue',label='rv-rv')\n",
    "#plt.plot(np.arange(start=1, stop=31, step=1),B[0:30],linestyle='-',color='red',label='duv-duv')\n",
    "#plt.plot(np.arange(start=1, stop=31, step=1),X[0:30],linestyle='--',color='red',label='lower bound duv-duv')\n",
    "#plt.fill_between(np.arange(start=1, stop=31, step=1),B[0:30],X[0:30], color='red', alpha=0.1,label='range of duv-rv')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),D[0:30],linestyle='-',color='purple',label='upper bound duv-rv')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),Y[0:30],linestyle='--',color='purple',label='lower bound duv-rv')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),D[0:30],Y[0:30], color='purple', alpha=0.1,label='range of duv-rv')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison the range of lower bound and upper bound with different type of uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"Comparison the range of lower bound and upper bound with different type of uncertainty\", fontsize = 20)\n",
    "plt.xlabel('n',fontsize=20)\n",
    "plt.ylabel('credibility', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),np.array(B[0:30]) - np.array(X[0:30]),linestyle='-',color='red',label='range of possibilistic case')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),np.array(D[0:30]) - np.array(Y[0:30]),linestyle='-',color='purple',label='range of mixed case')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try plotting lower bound of $p(y_{8}| y_{1:7})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = []\n",
    "I = []\n",
    "J = []\n",
    "i = 7 #time step that has problem\n",
    "def f(x):\n",
    "    c = norm(y[0][i], Pyn[i]**0.5).pdf(y[0][i]) #by substitute x0= (yn - rem )/coef we get mean = yn \n",
    "    return c- ((math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (c-norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i])))\n",
    "for x in np.arange(start=-50, stop=51, step=1):\n",
    "    G.append(f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"Lower bound of $p(y_{8}| y_{1:7})$ for different types of uncertainty when $\\sigma_{x_{0}} = 400, \\sigma_{x}=1,\\sigma_{y}=20$\", fontsize = 20)\n",
    "plt.xlabel('$x_{0}$',fontsize=20)\n",
    "plt.ylabel('credibility', fontsize=20)\n",
    "plt.plot(np.arange(start=-50, stop=51, step=1),G,linestyle='-',color='purple',label='lower bound duv-rv')\n",
    "plt.vlines(newMu0[i]-newP00[i]**0.5,0,f(newMu0[i]-newP00[i]**0.5),linestyle='--',color='green',label='$m_0 +- \\sigma_{0}$')\n",
    "plt.vlines(newMu0[i]+newP00[i]**0.5,0,f(newMu0[i]+newP00[i]**0.5),linestyle='--',color='green')\n",
    "plt.vlines(newMu0[i]-2*newP00[i]**0.5,0,f(newMu0[i]-2*newP00[i]**0.5),linestyle='--',color='blue',label='$m_0 +- 2\\sigma_{0}$')\n",
    "plt.vlines(newMu0[i]+2*newP00[i]**0.5,0,f(newMu0[i]+2*newP00[i]**0.5),linestyle='--',color='blue')\n",
    "plt.vlines(newMu0[i],0,f(newMu0[i]),linestyle='--',color='red',label='$m_0$')\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1 : $\\mu_0 =0 ,\\sigma_0 =400$\n",
    "## Model2 : $\\mu_0 =0 ,\\sigma_0 =10$(less variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior = N(x0;0,100)\n",
    "m0 = np.array([0.0]) #m0=0\n",
    "sig0 =10 #prior sigma , sig0=10\n",
    "P0 = np.array([sig0**2]) #large uncertainty of initial state sig0^2 \n",
    "\n",
    "(Mu0,P00,Mun,Pnn,Mcco,Mcre,Pc) = KS(y,m0,P0,F,H,U,V,n,1,n)\n",
    "\n",
    "#rv-rv case\n",
    "Mun1  = np.insert(Mun[0:n-1],0,m0) # mean xn-1| y1:n-1 i.e. x0, x1|y1, x2|y1:2, ..., xn-1|y1:n-1\n",
    "Pnn1  = np.insert(Pnn[0:n-1],0,P0) # var xn-1| y1:n-1\n",
    "Myn = []\n",
    "Pyn = []\n",
    "for i in np.arange(n):\n",
    "    Myn.append(np.matmul(H,np.matmul(F,[Mun1[i]])))  #mean yn| y1:n-1\n",
    "    Pyn.append(np.matmul(H,np.matmul(np.matmul(F,np.matmul([Pnn1[i]],F.transpose())) + U, H.transpose())) + V) \n",
    "    #var yn| y1:n-1\n",
    "\n",
    "#duv-rv case\n",
    "#yn|x0,y1:n-1\n",
    "Mcco1  = np.insert(Mcco[0:n-1],0,1) #coef of mean xn-1|x0,y1:n-1 i.e. x0, x1|x0,y1, x2|x0,y1:2, ..., xn-1|x0,y1:n-1 #x0 = 1*x + 0\n",
    "Mcre1  = np.insert(Mcre[0:n-1],0,0) #remainder of mean xn-1|x0,y1:n-1 \n",
    "Pc1  = np.insert(Pc[0:n-1],0,P0) #remainder of mean xn-1|x0,y1:n-1 \n",
    "coyn = []  #coef of mean yn|x0,y1:n-1\n",
    "reyn = []  #remainder of mean yn|x0,y1:n-1\n",
    "Pyn = [] #variance yn|x0,y1:n-1\n",
    "for i in np.arange(n):\n",
    "    coyn.append(np.matmul(H,np.matmul(F,[Mcco1[i]])))  \n",
    "    reyn.append(np.matmul(H,np.matmul(F,[Mcre1[i]])))  \n",
    "    Pyn.append((np.matmul(H,np.matmul(np.matmul(F,np.matmul([Pc1[i]],F.transpose())) + U, H.transpose())) + V)[0]) \n",
    "    \n",
    "#x0|y1:n-1\n",
    "newMu0 = np.insert(Mu0[0:n-1],0,m0) #mean x0|y1:n-1 i.e. x0, x0|y1, x0|y1:2, ..., x0|y1:n-1\n",
    "newP00 = np.insert(P00[0:n-1],0,P0) #variance x0|y1:n-1\n",
    "\n",
    "#rv-rv case for prob p(yn|y1:n-1)\n",
    "cred2 = []\n",
    "for i in np.arange(n):\n",
    "    cred2.append(norm(Myn[i],Pyn[i]**0.5).pdf(y[0][i])[0])\n",
    "    \n",
    "#upper bound for subjective prob p(yn|y1:n-1)\n",
    "D2=[]\n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return (math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i]))\n",
    "    #j1 = minimize(lambda x: -f(x),newMu0[i] + (newP00[i]**0.5)).x   ##set intial guess =m0 +- sig0\n",
    "    #j2 = minimize(lambda x: -f(x),newMu0[i] - (newP00[i]**0.5)).x\n",
    "    #fj = max(f(j1),f(j2))\n",
    "    fj = f(minimize(lambda x: -f(x),newMu0[i]).x)\n",
    "    D2.append(fj[0])  \n",
    "\n",
    "#lower bound for subjective prob p(yn|y1:n-1)    \n",
    "Y2 = [] \n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        c = norm(y[0][i], Pyn[i]**0.5).pdf(y[0][i]) #by substitute x0= (yn - rem )/coef we get mean = yn \n",
    "        return c- ((math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (c-norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i]))) \n",
    "    j1 = minimize(f,newMu0[i] + (newP00[i]**0.5)).x  ##set intial guess =m0 +- sig0\n",
    "    j2 = minimize(f,newMu0[i] - (newP00[i]**0.5)).x\n",
    "    fj = min(f(j1),f(j2))\n",
    "    Y2.append(fj[0])  \n",
    "    \n",
    "low = np.log10(np.array(Y)/np.array(D2))\n",
    "up = np.log10(np.array(D)/np.array(Y2))\n",
    "prob = np.log10(np.array(cred)/np.array(cred2))\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"log of Bayes factor $log_{10}(K)$ where  $ K= p(y_n| y_{1:n-1},M1) / p(y_n| y_{1:n-1},M2)$\", fontsize = 20)\n",
    "plt.xlabel('n',fontsize=20)\n",
    "plt.ylabel('$log_{10}(K)$', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),prob[0:30],linestyle='-',color='black',label='rv-rv')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),up[0:30],linestyle='-',color='green',label='upper bound')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),low[0:30],linestyle='--',color='green',label='lower bound')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[-3]*n,[-2]*n, color='red', alpha=0.5,edgecolor= 'none',label='decisive support M2')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[-2]*30,[-1]*30, color='red', alpha=0.4,edgecolor= 'none',label='strong support M2')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[-1]*30,[-0.5]*30, color='red', alpha=0.3,edgecolor= 'none',label='substantial support M2')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[-0.5]*30,[0]*30, color='red', alpha=0.2,edgecolor= 'none',label='weak support M2')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[0]*30,[0.5]*30, color='blue', alpha=0.2,edgecolor= 'none',label='weak support M1')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[0.5]*n,[1]*n, color='blue', alpha=0.3,edgecolor= 'none',label='substantial support M1')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[1]*n,[2]*n, color='blue', alpha=0.4,edgecolor= 'none',label='strong support M1')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[2]*n,[3]*n, color='blue', alpha=0.5,edgecolor= 'none',label='decisive support M1')\n",
    "plt.legend(loc='right',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1 : $\\sigma_x =1$\n",
    "## Model3 : $\\sigma_x =50$(more variance evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior = N(x0;0,100)\n",
    "m0 = np.array([0.0]) #m0=0\n",
    "sig0 =400 #prior sigma , sig0=400\n",
    "P0 = np.array([sig0**2]) #large uncertainty of initial state sig0^2 \n",
    "sigx = 50 #sigx=1\n",
    "sqrtU = np.array([[sigx]]) #sigma evolve\n",
    "U = np.matmul(sqrtU, sqrtU.transpose()) #variance evolve\n",
    "(Mu0,P00,Mun,Pnn,Mcco,Mcre,Pc) = KS(y,m0,P0,F,H,U,V,n,1,n)\n",
    "\n",
    "#rv-rv case\n",
    "Mun1  = np.insert(Mun[0:n-1],0,m0) # mean xn-1| y1:n-1 i.e. x0, x1|y1, x2|y1:2, ..., xn-1|y1:n-1\n",
    "Pnn1  = np.insert(Pnn[0:n-1],0,P0) # var xn-1| y1:n-1\n",
    "Myn = []\n",
    "Pyn = []\n",
    "for i in np.arange(n):\n",
    "    Myn.append(np.matmul(H,np.matmul(F,[Mun1[i]])))  #mean yn| y1:n-1\n",
    "    Pyn.append(np.matmul(H,np.matmul(np.matmul(F,np.matmul([Pnn1[i]],F.transpose())) + U, H.transpose())) + V) \n",
    "    #var yn| y1:n-1\n",
    "\n",
    "#duv-rv case\n",
    "#yn|x0,y1:n-1\n",
    "Mcco1  = np.insert(Mcco[0:n-1],0,1) #coef of mean xn-1|x0,y1:n-1 i.e. x0, x1|x0,y1, x2|x0,y1:2, ..., xn-1|x0,y1:n-1 #x0 = 1*x + 0\n",
    "Mcre1  = np.insert(Mcre[0:n-1],0,0) #remainder of mean xn-1|x0,y1:n-1 \n",
    "Pc1  = np.insert(Pc[0:n-1],0,P0) #remainder of mean xn-1|x0,y1:n-1 \n",
    "coyn = []  #coef of mean yn|x0,y1:n-1\n",
    "reyn = []  #remainder of mean yn|x0,y1:n-1\n",
    "Pyn = [] #variance yn|x0,y1:n-1\n",
    "for i in np.arange(n):\n",
    "    coyn.append(np.matmul(H,np.matmul(F,[Mcco1[i]])))  \n",
    "    reyn.append(np.matmul(H,np.matmul(F,[Mcre1[i]])))  \n",
    "    Pyn.append((np.matmul(H,np.matmul(np.matmul(F,np.matmul([Pc1[i]],F.transpose())) + U, H.transpose())) + V)[0]) \n",
    "    \n",
    "#x0|y1:n-1\n",
    "newMu0 = np.insert(Mu0[0:n-1],0,m0) #mean x0|y1:n-1 i.e. x0, x0|y1, x0|y1:2, ..., x0|y1:n-1\n",
    "newP00 = np.insert(P00[0:n-1],0,P0) #variance x0|y1:n-1\n",
    "\n",
    "#rv-rv case for prob p(yn|y1:n-1)\n",
    "cred3 = []\n",
    "for i in np.arange(n):\n",
    "    cred3.append(norm(Myn[i],Pyn[i]**0.5).pdf(y[0][i])[0])\n",
    "    \n",
    "#upper bound for subjective prob p(yn|y1:n-1)\n",
    "D3=[]\n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        return (math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i]))\n",
    "    #j1 = minimize(lambda x: -f(x),newMu0[i] + (newP00[i]**0.5)).x   ##set intial guess =m0 +- sig0\n",
    "    #j2 = minimize(lambda x: -f(x),newMu0[i] - (newP00[i]**0.5)).x\n",
    "    #fj = max(f(j1),f(j2))\n",
    "    fj = f(minimize(lambda x: -f(x),newMu0[i]).x)\n",
    "    D3.append(fj[0])  \n",
    "\n",
    "#lower bound for subjective prob p(yn|y1:n-1)    \n",
    "Y3 = [] \n",
    "for i in np.arange(n):\n",
    "    def f(x):\n",
    "        c = norm(y[0][i], Pyn[i]**0.5).pdf(y[0][i]) #by substitute x0= (yn - rem )/coef we get mean = yn \n",
    "        return c- ((math.exp((-1/(2*newP00[i]))*((x-newMu0[i])**2 )))* (c-norm(coyn[i]*x + reyn[i], Pyn[i]**0.5).pdf(y[0][i]))) \n",
    "    j1 = minimize(f,newMu0[i] + (newP00[i]**0.5)).x  ##set intial guess =m0 +- sig0\n",
    "    j2 = minimize(f,newMu0[i] - (newP00[i]**0.5)).x\n",
    "    fj = min(f(j1),f(j2))\n",
    "    Y3.append(fj[0])  \n",
    "    \n",
    "low3 = np.log10(np.array(Y)/np.array(D3))\n",
    "up3 = np.log10(np.array(D)/np.array(Y3))\n",
    "prob3 = np.log10(np.array(cred)/np.array(cred3))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.title(\"log of Bayes factor $log_{10}(K)$ where  $ K= p(y_n| y_{1:n-1},M1) / p(y_n| y_{1:n-1},M3)$\", fontsize = 20)\n",
    "plt.xlabel('n',fontsize=20)\n",
    "plt.ylabel('$log_{10}(K)$', fontsize=20)\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),prob3[0:30],linestyle='-',color='black',label='rv-rv')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),up3[0:30],linestyle='-',color='green',label='upper bound')\n",
    "plt.plot(np.arange(start=1, stop=31, step=1),low3[0:30],linestyle='--',color='green',label='lower bound')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[-3]*n,[-2]*n, color='red', alpha=0.5,edgecolor= 'none',label='decisive support M2')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[-2]*n,[-1]*n, color='red', alpha=0.4,edgecolor= 'none',label='strong support M2')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[-1]*30,[-0.5]*30, color='red', alpha=0.3,edgecolor= 'none',label='substantial support M3')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[-0.5]*30,[0]*30, color='red', alpha=0.2,edgecolor= 'none',label='weak support M3')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[0]*30,[0.5]*30, color='blue', alpha=0.2,edgecolor= 'none',label='weak support M1')\n",
    "plt.fill_between(np.arange(start=1, stop=31, step=1),[0.5]*30,[1]*30, color='blue', alpha=0.3,edgecolor= 'none',label='substantial support M1')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[1]*n,[2]*n, color='blue', alpha=0.4,edgecolor= 'none',label='strong support M1')\n",
    "#plt.fill_between(np.arange(start=1, stop=n+1, step=1),[2]*n,[3]*n, color='blue', alpha=0.5,edgecolor= 'none',label='decisive support M1')\n",
    "plt.legend(loc='right',fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
